{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial3: GAT implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementation of GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Official resources:\n",
    "* [Code](https://dsgiitr.com/blogs/gat/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple PyTorch Implementation of the Graph Attention layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GATLayer, self).__init__()\n",
    "      \n",
    "    def forward(self, input, adj):\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start from the forward method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Transformation\n",
    "\n",
    "$$\n",
    "\\bar{h'}_i = \\textbf{W}\\cdot \\bar{h}_i\n",
    "$$\n",
    "with $\\textbf{W}\\in\\mathbb R^{F'\\times F}$ and $\\bar{h}_i\\in\\mathbb R^{F}$.\n",
    "\n",
    "$$\n",
    "\\bar{h'}_i \\in \\mathbb{R}^{F'}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "in_features = 5\n",
    "out_features = 2\n",
    "nb_nodes = 3 # 3 nodes in the graph\n",
    "\n",
    "W = nn.Parameter(torch.zeros(size=(in_features, out_features))) #xavier parameter inizializator\n",
    "nn.init.xavier_uniform_(W.data, gain=1.414)\n",
    "\n",
    "input = torch.rand(nb_nodes,in_features) \n",
    "\n",
    "# linear transformation\n",
    "h = torch.mm(input, W)\n",
    "N = h.size()[0]\n",
    "\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f28b3f9490>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h[:, 0].detach().numpy(), h[:,1].detach().numpy(), \"o-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](AttentionMechanism.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 output features per node, each feature will be inputted into the attention network so we get an attention layer with 4 inputs and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "a = nn.Parameter(torch.zeros(size=(2*out_features, 1))) #xavier parameter inizializator\n",
    "nn.init.xavier_uniform_(a.data, gain=1.414)\n",
    "print(a.shape)\n",
    "\n",
    "leakyrelu = nn.LeakyReLU(0.2)  # LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector with the possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_input = (\n",
    "    torch.cat(\n",
    "        [h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1\n",
    "    )\n",
    "    .view(N, -1, 2 * out_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](a_input.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = leakyrelu(torch.matmul(a_input, a).squeeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 4]) torch.Size([4, 1])\n",
      "\n",
      "torch.Size([3, 3, 1])\n",
      "\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a_input.shape,a.shape)\n",
    "print(\"\")\n",
    "print(torch.matmul(a_input,a).shape)\n",
    "print(\"\")\n",
    "print(torch.matmul(a_input,a).squeeze(2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3354, -0.2286, -0.1423],\n",
       "        [-0.0879,  0.0946,  0.5262],\n",
       "        [-0.1058,  0.0050,  0.4367]], grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph with 3 nodes -> we get a 3x3 attention matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
       "        [-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
       "        [-9.0000e+15, -9.0000e+15, -9.0000e+15]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masked Attention\n",
    "adj = torch.randint(2, (3, 3)) # Randomly create a matrix of 0s and 1s of shape (3, 3)\n",
    "\n",
    "zero_vec  = -9e15*torch.ones_like(e) # tensor of same shape as e but with tiny values\n",
    "print(zero_vec.shape)\n",
    "zero_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 0]]) \n",
      " tensor([[-0.3354, -0.2286, -0.1423],\n",
      "        [-0.0879,  0.0946,  0.5262],\n",
      "        [-0.1058,  0.0050,  0.4367]], grad_fn=<LeakyReluBackward0>) \n",
      " tensor([[-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
      "        [-9.0000e+15, -9.0000e+15, -9.0000e+15],\n",
      "        [-9.0000e+15, -9.0000e+15, -9.0000e+15]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.3539e-01, -9.0000e+15, -1.4229e-01],\n",
       "        [-8.7860e-02,  9.4555e-02,  5.2618e-01],\n",
       "        [-1.0576e-01,  5.0294e-03, -9.0000e+15]], grad_fn=<SWhereBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = torch.where(adj > 0, e, zero_vec)\n",
    "print(adj,\"\\n\",e,\"\\n\",zero_vec)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(attention, dim=1)\n",
    "h_prime   = torch.matmul(attention, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4519, 0.0000, 0.5481],\n",
       "        [0.2470, 0.2965, 0.4565],\n",
       "        [0.4723, 0.5277, 0.0000]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5763, -0.2426],\n",
       "        [ 0.5146, -0.0829],\n",
       "        [ 0.2663, -0.3556]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h_prime vs h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5763, -0.2426],\n",
      "        [ 0.5146, -0.0829],\n",
      "        [ 0.2663, -0.3556]], grad_fn=<MmBackward0>) \n",
      " tensor([[ 0.2912, -0.8082],\n",
      "        [ 0.2441,  0.0495],\n",
      "        [ 0.8113,  0.2237]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(h_prime,\"\\n\",h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GATLayer, self).__init__()\n",
    "        \n",
    "        '''\n",
    "        TODO\n",
    "        '''\n",
    "        \n",
    "    def forward(self, input, adj):\n",
    "        # Linear Transformation\n",
    "        h = torch.mm(input, self.W) # matrix multiplication\n",
    "        N = h.size()[0]\n",
    "\n",
    "        # Attention Mechanism\n",
    "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)\n",
    "        e       = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
    "\n",
    "        # Masked Attention\n",
    "        zero_vec  = -9e15*torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, zero_vec)\n",
    "        \n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime   = torch.matmul(attention, h)\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.dropout       = dropout        # drop prob = 0.6\n",
    "        self.in_features   = in_features    # \n",
    "        self.out_features  = out_features   # \n",
    "        self.alpha         = alpha          # LeakyReLU with negative input slope, alpha = 0.2\n",
    "        self.concat        = concat         # conacat = True for all layers except the output layer.\n",
    "\n",
    "        \n",
    "        # Xavier Initialization of Weights\n",
    "        # Alternatively use weights_init to apply weights of choice \n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        \n",
    "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "        # LeakyReLU\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # Linear Transformation\n",
    "        h = torch.mm(input, self.W) # matrix multiplication\n",
    "        N = h.size()[0]\n",
    "        print(N)\n",
    "\n",
    "        # Attention Mechanism\n",
    "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)\n",
    "        e       = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
    "\n",
    "        # Masked Attention\n",
    "        zero_vec  = -9e15*torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, zero_vec)\n",
    "        \n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime   = torch.matmul(attention, h)\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes in Cora: 7\n",
      "Number of Node Features in Cora: 1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name_data = 'Cora'\n",
    "dataset = Planetoid(root='/tmp/' + name_data, name = name_data)\n",
    "dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "print(f\"Number of Classes in {name_data}:\", dataset.num_classes)\n",
    "print(f\"Number of Node Features in {name_data}:\", dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor(1.9464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5742, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hidden = 8\n",
    "        self.in_head = 8\n",
    "        self.out_head = 1\n",
    "        \n",
    "        self.conv1 = GATConv(dataset.num_features, self.hidden, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hidden*self.in_head, dataset.num_classes, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "                \n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = GAT().to(device)\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    if epoch%200 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8230\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pygnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3622d963afec81144becab79eb84bb8bdf5e955208d50384beb820a9b18af519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
